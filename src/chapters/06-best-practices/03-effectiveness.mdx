import { Meta } from '@storybook/addon-docs/blocks';
import { Callout } from '../../components/Callout';
import { CodeBlock } from '../../components/CodeBlock';
import { ComparisonTable } from '../../components/ComparisonTable';
import { PlotlyChart } from '../../components/PlotlyChart';
import { MermaidDiagram } from '../../components/MermaidDiagram';
import { ChapterNav } from '../../components/ChapterNav';

<Meta title="Part 6: 모범 사례/효과 측정" />

# 효과 측정

> AI 코딩 도구의 ROI를 측정하고 개선하는 방법

## 측정의 목적

<Callout type="info" title="왜 측정하나요?">
  "측정하지 않으면 개선할 수 없다." AI 도구 도입의 효과를 객관적으로 파악하고,
  더 효과적인 활용 방법을 찾기 위해 측정이 필요합니다.
</Callout>

| 목적 | 설명 |
|------|------|
| **ROI 증명** | AI 도구 도입의 투자 대비 효과 입증 |
| **개선 영역 식별** | 더 효과적으로 활용할 수 있는 영역 파악 |
| **모범 사례 발굴** | 성공적인 활용 패턴 공유 |
| **교육 방향 설정** | 팀 교육의 우선순위 결정 |

## 핵심 지표 (KPIs)

### 1. 생산성 지표

<ComparisonTable
  title="생산성 측정"
  headers={['지표', '측정 방법', '목표']}
  rows={[
    { feature: 'PR 생성 속도', values: ['PR 생성까지 평균 시간', '30% 단축'] },
    { feature: '기능 완료율', values: ['스프린트당 완료 스토리', '20% 향상'] },
    { feature: '코드 리뷰 시간', values: ['PR 리뷰 평균 시간', '40% 단축'] },
  ]}
/>

### 활동별 AI 도구 효율성

<Callout type="info" title="출처: Techreviewer 2025 AI Development Workflows 조사">
  아래 수치는 Techreviewer의 2025년 AI 개발 워크플로우 조사에서 산출된 효율성 점수(0~1.0)입니다.
  1.0에 가까울수록 AI 도구가 해당 작업에서 높은 효율을 보인다는 의미입니다.
</Callout>

<PlotlyChart
  title="활동별 AI 도구 효율성 점수 (Techreviewer 2025)"
  data={[
    {
      x: ['코드 생성/완성', '문서 작성', '리팩토링', '버그 수정/디버깅', '테스트 작성', 'DB 쿼리'],
      y: [0.93, 0.92, 0.87, 0.79, 0.71, 0.58],
      type: 'bar',
      marker: {
        color: ['#da7756', '#da7756', '#e8a98e', '#e8a98e', '#e8a98e', '#f0cec0'],
        line: { color: '#d4cdc4', width: 1 },
      },
      text: ['0.93', '0.92', '0.87', '0.79', '0.71', '0.58'],
      textposition: 'outside',
      textfont: { color: '#2d2a26', size: 13 },
      hovertemplate: '%{x}: %{y}<extra></extra>',
    },
  ]}
  layout={{
    yaxis: { title: '효율성 점수 (0-1.0)', range: [0, 1.15] },
    margin: { t: 20, b: 80 },
  }}
  height={350}
/>

### 2. 품질 지표

| 지표 | 측정 방법 | 목표 |
|------|----------|------|
| 버그 발생률 | 릴리스당 버그 수 | 20% 감소 |
| 테스트 커버리지 | 코드 커버리지 % | 10% 향상 |
| 코드 리뷰 수정 요청 | PR당 수정 요청 수 | 30% 감소 |
| 기술 부채 | SonarQube 점수 | 유지/개선 |

### 3. 팀 만족도

<CodeBlock
  code={`설문 항목 (1-5점):

1. AI 도구가 일상 업무에 도움이 되나요?
2. 반복적인 작업이 줄었나요?
3. 새로운 기술/코드베이스 학습에 도움이 되나요?
4. 코드 품질에 대한 자신감이 높아졌나요?
5. AI 도구 없이 작업하고 싶나요? (역점수)`}
  language="text"
  filename="개발자 경험 설문"
/>

## 업계 조사 기반 도입 효과

<Callout type="info" title="출처">
  아래 수치는 2025년 업계 조사 결과를 종합한 것입니다.
  팀 환경에 따라 결과가 다를 수 있으므로, 자체 측정을 병행하는 것이 중요합니다.
</Callout>

<ComparisonTable
  title="AI 코딩 도구 도입 효과 (2025 업계 조사 종합)"
  headers={['지표', '조사 결과', '출처']}
  rows={[
    { feature: '생산성 향상', values: ['AI 도구를 폭넓게 활용하는 팀은 작업 완료량 21% 증가, 개발자당 PR 수 47% 증가', 'index.dev 2025'] },
    { feature: '팀 생산성 향상', values: ['62%의 응답자가 AI 도구로 25% 이상 개발 속도 향상을 체감', 'Jellyfish 2025 State of Engineering Management'] },
    { feature: '코드 리뷰 품질', values: ['AI 코드 리뷰 활용 팀의 81%가 품질 개선을 경험 (미사용 팀 55%)', 'Qodo 2025 State of AI Code Quality'] },
    { feature: '테스트 신뢰도', values: ['AI 테스트 작성 활용 시 신뢰도 61% (미사용 시 27%)', 'Qodo 2025 State of AI Code Quality'] },
    { feature: '전체 코드 중 AI 비율', values: ['2024년 기준 전체 코드의 41%가 AI 도구로 작성 또는 보조', 'GitClear 2024 (2.11억 변경 라인 분석)'] },
  ]}
/>

## 개선 사이클

<MermaidDiagram
  chart={`flowchart TB
    M["📊 1. 측정 (Measure)<br/>주간/월간 지표 수집<br/>팀 설문 조사"]
    A["🔍 2. 분석 (Analyze)<br/>트렌드 파악<br/>병목 지점 식별"]
    I["🔧 3. 개선 (Improve)<br/>프롬프트 업데이트<br/>워크플로우 최적화"]
    S["📢 4. 공유 (Share)<br/>성공 사례 문서화<br/>가이드라인 업데이트"]
    M --> A --> I --> S --> M
    style M fill:#fdf2ee,stroke:#2563eb,color:#2d2a26
    style A fill:#fdf2ee,stroke:#9333ea,color:#2d2a26
    style I fill:#fdf2ee,stroke:#16a34a,color:#2d2a26
    style S fill:#fdf2ee,stroke:#d97706,color:#2d2a26`}
  title="MAIS 개선 사이클"
  caption="측정 → 분석 → 개선 → 공유의 순환 구조로 지속적으로 효과를 높여갑니다"
/>

## 주의사항

<Callout type="warning" title="측정하지 말아야 할 것">
  - **순수 코드 라인 수**: 품질 없는 양적 지표는 의미 없음
  - **개인별 비교**: 경쟁을 유발하고 협업을 저해함
  - **AI 의존도 자체**: 도구 활용과 의존은 다름
</Callout>

### 올바른 관점

- 팀 전체의 성과 향상에 집중
- 품질과 생산성의 균형
- 장기적인 트렌드 관찰
- 정성적 피드백의 가치 인정

<Callout type="tip" title="Claude Code OTel로 자동 측정">
  Claude Code의 OpenTelemetry 지원으로 `claude_code.lines_of_code.count`, `claude_code.cost.usage`,
  `claude_code.active_time.total` 등의 메트릭을 자동 수집할 수 있습니다.
  Part 1의 엔터프라이즈 보안 챕터에서 OTel 설정 방법을 참고하세요.
</Callout>

<ChapterNav
  prev={{ title: '팀 협업', path: '/docs/part-6--모범-사례-팀-협업' }}
/>
