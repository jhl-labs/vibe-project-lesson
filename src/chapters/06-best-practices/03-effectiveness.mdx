import { Meta } from '@storybook/blocks';
import { Callout } from '../../components/Callout';
import { CodeBlock } from '../../components/CodeBlock';
import { ComparisonTable } from '../../components/ComparisonTable';
import { Quiz } from '../../components/Quiz';
import { ChapterNav } from '../../components/ChapterNav';

<Meta title="Part 6: 모범 사례/효과 측정" />

# 효과 측정

> AI 코딩 도구의 ROI를 측정하고 개선하는 방법

## 측정의 목적

<Callout type="info" title="왜 측정하나요?">
  "측정하지 않으면 개선할 수 없다." AI 도구 도입의 효과를 객관적으로 파악하고,
  더 효과적인 활용 방법을 찾기 위해 측정이 필요합니다.
</Callout>

| 목적 | 설명 |
|------|------|
| **ROI 증명** | AI 도구 도입의 투자 대비 효과 입증 |
| **개선 영역 식별** | 더 효과적으로 활용할 수 있는 영역 파악 |
| **모범 사례 발굴** | 성공적인 활용 패턴 공유 |
| **교육 방향 설정** | 팀 교육의 우선순위 결정 |

## 핵심 지표 (KPIs)

### 1. 생산성 지표

<ComparisonTable
  title="생산성 측정"
  headers={['지표', '측정 방법', '목표']}
  rows={[
    { feature: 'PR 생성 속도', values: ['PR 생성까지 평균 시간', '30% 단축'] },
    { feature: '기능 완료율', values: ['스프린트당 완료 스토리', '20% 향상'] },
    { feature: '코드 리뷰 시간', values: ['PR 리뷰 평균 시간', '40% 단축'] },
  ]}
/>

### 시간 절약 벤치마크

| 활동 | 기존 시간 | AI 활용 시간 | 절감률 |
|------|----------|-------------|--------|
| 보일러플레이트 작성 | 2시간 | 15분 | **87%** |
| 테스트 코드 작성 | 1시간 | 20분 | **67%** |
| 문서화 | 3시간 | 30분 | **83%** |
| 코드 리뷰 준비 | 30분 | 10분 | **67%** |
| 버그 수정 | 2시간 | 45분 | **62%** |

### 2. 품질 지표

| 지표 | 측정 방법 | 목표 |
|------|----------|------|
| 버그 발생률 | 릴리스당 버그 수 | 20% 감소 |
| 테스트 커버리지 | 코드 커버리지 % | 10% 향상 |
| 코드 리뷰 수정 요청 | PR당 수정 요청 수 | 30% 감소 |
| 기술 부채 | SonarQube 점수 | 유지/개선 |

### 3. 팀 만족도

<CodeBlock
  code={`설문 항목 (1-5점):

1. AI 도구가 일상 업무에 도움이 되나요?
2. 반복적인 작업이 줄었나요?
3. 새로운 기술/코드베이스 학습에 도움이 되나요?
4. 코드 품질에 대한 자신감이 높아졌나요?
5. AI 도구 없이 작업하고 싶나요? (역점수)`}
  language="text"
  filename="개발자 경험 설문"
/>

## 도입 전후 비교

<CodeBlock
  code={`도입 전 (Baseline):
├── 평균 PR 작성 시간: 4시간
├── PR당 수정 요청: 3회
├── 테스트 커버리지: 55%
└── 문서화 완성도: 40%

도입 후 (3개월):
├── 평균 PR 작성 시간: 2시간 (-50%)
├── PR당 수정 요청: 1.5회 (-50%)
├── 테스트 커버리지: 75% (+36%)
└── 문서화 완성도: 85% (+112%)`}
  language="text"
  filename="도입 전후 비교"
/>

## 개선 사이클

<CodeBlock
  code={`    ┌───────────┐
    │  1. 측정  │ ← 주간/월간 지표 수집
    │ (Measure) │   팀 설문 조사
    └─────┬─────┘
          │
    ┌─────▼─────┐
    │  2. 분석  │ ← 트렌드 파악
    │ (Analyze) │   병목 지점 식별
    └─────┬─────┘
          │
    ┌─────▼─────┐
    │  3. 개선  │ ← 프롬프트 업데이트
    │ (Improve) │   워크플로우 최적화
    └─────┬─────┘
          │
    ┌─────▼─────┐
    │  4. 공유  │ ← 성공 사례 문서화
    │  (Share)  │   가이드라인 업데이트
    └─────┬─────┘
          │
          └────────→ 반복`}
  language="text"
  filename="MAIS 개선 사이클"
/>

## 주의사항

<Callout type="warning" title="측정하지 말아야 할 것">
  - **순수 코드 라인 수**: 품질 없는 양적 지표는 의미 없음
  - **개인별 비교**: 경쟁을 유발하고 협업을 저해함
  - **AI 의존도 자체**: 도구 활용과 의존은 다름
</Callout>

### 올바른 관점

- 팀 전체의 성과 향상에 집중
- 품질과 생산성의 균형
- 장기적인 트렌드 관찰
- 정성적 피드백의 가치 인정

<Quiz
  title="효과 측정 이해도 확인"
  questions={[
    {
      question: 'AI 도구 효과 측정 시 가장 중요한 것은?',
      options: ['코드 라인 수', '개인별 AI 사용량', '팀 전체의 품질과 생산성 균형', 'AI 도구 비용'],
      correctIndex: 2,
      explanation: '효과 측정은 팀 전체의 성과 향상에 집중해야 하며, 품질과 생산성의 균형을 유지하는 것이 중요합니다.',
    },
    {
      question: '개선 사이클의 올바른 순서는?',
      options: ['공유 → 측정 → 분석 → 개선', '측정 → 분석 → 개선 → 공유', '분석 → 개선 → 측정 → 공유', '개선 → 공유 → 측정 → 분석'],
      correctIndex: 1,
      explanation: 'MAIS 사이클은 측정(Measure) → 분석(Analyze) → 개선(Improve) → 공유(Share)의 순서로 반복합니다.',
    },
  ]}
/>

<ChapterNav
  prev={{ title: '팀 협업', path: '/docs/part-6--모범-사례-팀-협업' }}
/>
