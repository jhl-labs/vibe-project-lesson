import { Meta } from '@storybook/addon-docs/blocks';
import { Callout } from '../../components/Callout';
import { CodeBlock } from '../../components/CodeBlock';
import { ComparisonTable } from '../../components/ComparisonTable';
import { MermaidDiagram } from '../../components/MermaidDiagram';
import { DataTable } from '../../components/DataTable';
import { ChapterNav } from '../../components/ChapterNav';

<Meta title="Part 6: 모범 사례/팀 협업" />

# 팀 협업

> AI 코드와 팀 워크플로우의 통합

## 왜 AI 시대의 팀 협업이 다른가

AI 코딩 에이전트 도입은 개인 생산성만의 문제가 아닙니다.
AI가 짧은 시간에 대량의 코드를 생성할 수 있게 되면서,
**리뷰 병목, PR 크기 증가, 코드 이해도 저하** 같은 새로운 팀 차원의 과제가 생겨납니다.

[Faros AI의 2025년 연구](https://www.faros.ai/blog/ai-productivity-paradox-2025)(1,255개 팀, 10,000+ 개발자)에 따르면,
AI 고도 활용 팀에서 개인 PR 생성량은 47% 증가했지만 PR 리뷰 시간은 91% 증가했습니다.
개인의 속도가 팀의 성과로 이어지려면, **워크플로우 전체를 함께 설계**해야 합니다.

<Callout type="important" title="핵심 원칙">
  AI가 생성한 코드의 최종 책임은 항상 커밋한 개발자에게 있습니다.
  "AI가 만들었으니 모르겠다"는 리뷰 코멘트나 장애 보고서에서 통하지 않습니다.
</Callout>

## AI 코딩 팀 워크플로우

팀에서 AI 코딩 에이전트를 사용하는 전형적인 흐름입니다.

<MermaidDiagram
  chart={`flowchart LR
    A["작업 할당"] --> B["AI로 코드 생성"]
    B --> C["개발자 검증"]
    C --> D["PR 제출"]
    D --> E["AI 코드 리뷰 보조"]
    E --> F["인간 리뷰어 검토"]
    F --> G{"승인?"}
    G -->|Yes| H["머지 & 배포"]
    G -->|No| I["수정"]
    I --> C

    B -.-> B1["CLAUDE.md 규칙 적용"]
    B -.-> B2["Hook 자동 검사"]
    D -.-> D1["Co-Authored-By 표기"]
    D -.-> D2["AI 사용 내역 기록"]
    F -.-> F1["환각 검사"]
    F -.-> F2["보안 검증"]

    style A fill:#e8f5e9,stroke:#4caf50,color:#333
    style H fill:#e8f5e9,stroke:#4caf50,color:#333
    style G fill:#fff9c4,stroke:#f9a825,color:#333`}
  title="AI 코딩 팀 워크플로우"
  caption="AI 생성 코드는 개발자 검증과 인간 리뷰를 반드시 거칩니다"
/>

### 책임 체계

<ComparisonTable
  title="AI 코드 협업 역할과 책임"
  headers={['역할', '핵심 책임', '구체적 행동']}
  rows={[
    { feature: '코드 작성자', values: ['AI 생성 코드 검토, 이해, 커밋', 'PR에 AI 사용 내역 명시, 모든 코드를 설명할 수 있어야 함'] },
    { feature: '코드 리뷰어', values: ['AI 코드 포함 전체 PR 리뷰', '환각 검사, 보안 확인, 과도한 복잡성 점검'] },
    { feature: '팀 리드', values: ['AI 활용 가이드라인 수립/관리', '.claude/ 팀 설정 표준화, 리뷰 프로세스 설계'] },
    { feature: '보안 담당', values: ['AI 코드 보안 정책 수립/검증', 'Hook 보안 규칙 관리, 정기 보안 감사'] },
  ]}
/>

## .claude/ 팀 설정 공유

Claude Code의 `.claude/` 디렉토리를 Git으로 관리하면 팀 전체가 동일한 AI 동작 규칙을 공유할 수 있습니다.

### 팀 공유 대상 파일

<ComparisonTable
  title=".claude/ 디렉토리 — Git 공유 여부"
  headers={['파일/디렉토리', 'Git 공유', '용도', '설정 주체']}
  rows={[
    { feature: '.claude/settings.json', values: ['yes', '팀 공통 권한/Hook 설정', '팀 리드'] },
    { feature: '.claude/commands/', values: ['yes', '팀 공용 슬래시 커맨드', '팀 전체'] },
    { feature: '.claude/skills/', values: ['yes', '팀 공용 스킬', '시니어/리드'] },
    { feature: 'CLAUDE.md', values: ['yes', '프로젝트 컨벤션/규칙', '팀 전체'] },
    { feature: 'CLAUDE.local.md', values: ['no (.gitignore)', '개인 설정/선호', '개인'] },
    { feature: '.claude/settings.local.json', values: ['no (.gitignore)', '개인 권한 오버라이드', '개인'] },
  ]}
/>

### 팀 표준 설정 예시

<CodeBlock
  code={`// .claude/settings.json — 팀 공통 설정
{
  "permissions": {
    "allow": [
      "Read",
      "Glob",
      "Grep",
      "Bash(npm test)",
      "Bash(npm run lint)",
      "Bash(npm run build)"
    ],
    "deny": [
      "Bash(curl *)",
      "Bash(wget *)",
      "Bash(rm -rf *)",
      "Edit(package-lock.json)",
      "Read(.env*)"
    ]
  }
}

// 팀원은 CLAUDE.local.md와 settings.local.json으로 개인 설정을 오버라이드할 수 있습니다.
// 단, deny는 팀 설정이 항상 우선합니다.`}
  language="json"
  filename=".claude/settings.json — 팀 표준"
/>

### 팀 공용 커맨드 예시

<CodeBlock
  code={`---
description: PR 제출 전 최종 점검을 수행합니다
---

다음 순서로 점검을 수행하세요:

1. npm run lint — 린트 오류가 있으면 수정
2. npm test — 테스트 실패가 있으면 수정
3. git diff --staged — 변경 내용 요약
4. 민감 정보(API 키, 비밀번호, .env 참조) 포함 여부 확인
5. Co-Authored-By 태그 포함 여부 확인

모든 점검 통과 시 "PR 준비 완료" 메시지 출력`}
  language="markdown"
  filename=".claude/commands/pr-check.md"
/>

## PR에서의 AI 사용 표기

AI를 사용한 코드가 PR에 포함될 때, **무엇을 AI가 만들었고 개발자가 무엇을 검증했는지**를
명시하면 리뷰어의 검토 효율이 높아지고, 향후 감사 추적(audit trail)에도 도움이 됩니다.

### PR 템플릿 자동화

<CodeBlock
  code={`<!-- .github/PULL_REQUEST_TEMPLATE.md -->
## 변경 사항

<!-- 이 PR에서 변경한 내용을 설명하세요 -->

## AI 지원 여부

- [ ] 이 PR은 AI 에이전트의 도움을 받아 작성되었습니다

### AI 사용 내역 (해당 시)

| 작업 | 파일 | AI 기여도 |
|------|------|----------|
|      |      | 초안 생성 / 리팩토링 제안 / 테스트 생성 |

### 개발자 검증

- [ ] 모든 AI 생성 코드를 직접 검토했습니다
- [ ] 코드의 동작을 이해하고 설명할 수 있습니다
- [ ] 보안 취약점을 확인했습니다 (Part 6 보안 체크리스트)
- [ ] 테스트를 실행하여 검증했습니다
- [ ] AI가 추천한 새 의존성이 있다면 실존 여부를 확인했습니다`}
  language="markdown"
  filename=".github/PULL_REQUEST_TEMPLATE.md"
/>

### 커밋 표기

<CodeBlock
  code={`# AI 지원 커밋 표기 (Co-Authored-By)
git commit -m "feat(auth): add JWT refresh token support

- Implement refresh token rotation
- Add token blacklist for logout

Co-Authored-By: Claude <noreply@anthropic.com>"`}
  language="bash"
  filename="AI 지원 커밋 예시"
/>

<Callout type="tip" title="Claude Code의 자동 표기">
  Claude Code는 커밋 시 자동으로 `Co-Authored-By: Claude` 태그를 추가합니다.
  이 태그는 GitHub에서 공동 작성자로 표시되며, git log에서 AI 지원 커밋을 필터링할 수 있습니다.
</Callout>

## AI 시대 코드 리뷰 워크플로우

AI가 생성한 코드를 리뷰할 때는 일반 코드 리뷰에 추가적인 확인 항목이 필요합니다.
기존의 "로직이 맞는가?"에서 "AI가 만든 코드를 작성자가 이해하고 있는가?"까지 리뷰 범위가 확장됩니다.

### AI 코드 리뷰의 3단계 프로세스

<MermaidDiagram
  chart={`flowchart TB
    subgraph STAGE1["1단계: 자동 검증"]
      A1["린트/포맷 검사"] --> A2["타입 체크"]
      A2 --> A3["단위 테스트"]
      A3 --> A4["보안 스캔 SAST"]
      A4 --> A5["의존성 취약점 검사"]
    end

    subgraph STAGE2["2단계: AI 보조 리뷰"]
      B1["AI가 PR diff 분석"] --> B2["잠재적 버그 탈지"]
      B2 --> B3["코딩 컨벤션 위반 식별"]
      B3 --> B4["테스트 커버리지 확인"]
    end

    subgraph STAGE3["3단계: 인간 리뷰어 심층 검토"]
      C1["비즈니스 로직 검증"] --> C2["작성자 이해도 확인"]
      C2 --> C3["아키텍처 적합성 평가"]
      C3 --> C4["환각 검사"]
      C4 --> C5["최종 승인/반려"]
    end

    STAGE1 --> STAGE2
    STAGE2 --> STAGE3

    style STAGE1 fill:#e3f2fd,stroke:#1976d2,color:#333
    style STAGE2 fill:#fff3e0,stroke:#f57c00,color:#333
    style STAGE3 fill:#e8f5e9,stroke:#4caf50,color:#333`}
  title="AI 코드 리뷰 3단계 프로세스"
  caption="자동 검증 -> AI 보조 리뷰 -> 인간 심층 검토 순서로 진행합니다"
/>

### 일반 코드 vs AI 코드 리뷰

<ComparisonTable
  title="일반 코드 vs AI 코드 리뷰 항목"
  headers={['항목', '일반 코드', 'AI 생성 코드']}
  rows={[
    { feature: '기능 검증', values: ['yes', 'yes'] },
    { feature: '코딩 컨벤션', values: ['yes', 'yes'] },
    { feature: '보안 검사', values: ['yes', 'yes (강화)'] },
    { feature: '작성자 이해도 확인', values: ['partial', 'yes (필수)'] },
    { feature: '과도한 복잡성 확인', values: ['partial', 'yes (필수)'] },
    { feature: '불필요한 코드 확인', values: ['partial', 'yes (필수)'] },
    { feature: 'AI 환각 검사', values: ['no', 'yes'] },
    { feature: '의존성 실존 확인', values: ['no', 'yes'] },
  ]}
/>

### AI 코드 리뷰 실전 포인트

AI가 생성한 코드에서 흔히 발견되는 문제와 리뷰 시 확인 방법입니다.

<CodeBlock
  code={`// ⚠️ AI 코드 리뷰 포인트 1: 환각 라이브러리
// AI가 존재하지 않는 라이브러리를 import하는 경우
import { validateEmail } from 'express-validator-plus'; // ❌ 실존하지 않는 패키지
import { body, validationResult } from 'express-validator'; // ✅ 실제 패키지

// 리뷰어 행동: npm view express-validator-plus 로 존재 여부 확인

// ⚠️ AI 코드 리뷰 포인트 2: 존재하지 않는 API
const result = await response.json.parse(); // ❌ .json.parse()는 미존재
const result = await response.json();       // ✅ 올바른 API

// ⚠️ AI 코드 리뷰 포인트 3: 과도한 추상화
// AI는 "좋은 코드"를 작성하려다 불필요한 패턴을 추가하는 경향이 있음
class UserRepositoryFactory {              // ❌ 단순 CRUD에 Factory 패턴
  createRepository(type: string) { ... }
}
const userRepo = prisma.user;              // ✅ 충분히 단순한 구현

// ⚠️ AI 코드 리뷰 포인트 4: Deprecated API
const buf = new Buffer('hello');           // ❌ Node.js 6+에서 deprecated
const buf = Buffer.from('hello');          // ✅ 현재 API`}
  language="typescript"
  filename="AI 코드 리뷰 포인트"
/>

<Callout type="warning" title="AI 환각 (Hallucination) 주의">
  AI가 존재하지 않는 API, 라이브러리, 메서드를 사용하는 코드를 생성할 수 있습니다.
  코드 리뷰 시 새로 추가된 import와 API 호출이 실제로 존재하는지 확인하세요.
  특히 `npm view [패키지명]`으로 패키지 존재 여부를, 공식 문서에서 API 존재 여부를 검증하세요.
</Callout>

### 리뷰어를 위한 질문 체크리스트

<CodeBlock
  code={`## AI 코드 리뷰 질문 목록 (리뷰어용)

### 이해도 확인
- [ ] 작성자에게 "이 함수가 왜 이 로직을 사용하는지" 물어봄
- [ ] 작성자가 AI 출력을 그대로 수용했는지, 수정했는지 확인

### 환각 검사
- [ ] 새로 추가된 의존성이 npm/PyPI에 실제 존재하는지 확인
- [ ] 사용된 API/메서드가 해당 라이브러리 버전에 존재하는지 확인
- [ ] CLI 플래그나 설정 옵션이 공식 문서에 있는지 확인

### 코드 품질
- [ ] 불필요한 추상화나 디자인 패턴이 없는지 확인
- [ ] 유사한 코드가 프로젝트에 이미 존재하지 않는지 확인
- [ ] 에러 메시지가 디버깅에 유용한지 확인

### 보안 (Part 6 보안 챕터 참조)
- [ ] 하드코딩된 시크릿 없음
- [ ] SQL 파라미터화, XSS 방지 확인
- [ ] 새 의존성의 보안 취약점 확인`}
  language="markdown"
  filename="AI 코드 리뷰 체크리스트"
/>

### 리뷰 코멘트 작성 가이드

AI 생성 코드에 대한 리뷰 코멘트는 일반 코드 리뷰보다 구체적이어야 합니다.
"왜 이렇게 했는지"가 아니라 "이 코드를 이해하고 있는지"를 확인하는 방향으로 작성합니다.

<CodeBlock
  code={`## 리뷰 코멘트 예시

### ❌ 비효과적인 코멘트
"이 부분 수정해주세요."
"AI가 왜 이렇게 만들었는지 모르겠네요."

### ✅ 효과적인 코멘트
"이 함수에서 에러가 발생하면 상위 호출자에게
어떤 값이 반환되나요? 의도한 동작인지 확인 부탁드립니다."

"express-validator-plus 패키지를 사용하고 있는데,
npm에서 확인이 안 됩니다. 실존 여부 확인해주세요."

"Factory 패턴이 적용되어 있는데, 현재 User 타입만
사용하고 있어 단순 구현으로도 충분해 보입니다.
이 추상화가 필요한 구체적인 시나리오가 있나요?"

### ✅ 이해도 확인 코멘트
"이 정규표현식이 어떤 입력을 매칭하는지 설명해주실 수 있나요?"
"이 재귀 함수의 종료 조건이 어떤 상황에서 만족되는지 알려주세요."`}
  language="markdown"
  filename="AI 코드 리뷰 코멘트 가이드"
/>

---

## PR 크기 관리 전략

AI가 대량의 코드를 빠르게 생성할 수 있으므로, PR 크기가 급격히 커질 수 있습니다.
Faros AI의 연구에 따르면 AI 고도 활용 팀에서 PR 크기가 **154% 증가**했고,
이는 리뷰 시간 증가의 주요 원인이 됩니다.

### PR 크기 가이드라인

<ComparisonTable
  title="PR 크기별 권장 사항"
  headers={['PR 크기', '변경 라인 수', '리뷰 시간', '권장 여부']}
  rows={[
    { feature: '소형', values: ['~200줄 이하', '30분 이내', 'yes'] },
    { feature: '중형', values: ['200~500줄', '1시간 이내', 'partial'] },
    { feature: '대형', values: ['500줄 이상', '수 시간', 'no'] },
  ]}
/>

### AI 대량 변경을 관리하는 전략

<CodeBlock
  code={`# 1. 작업 단위 분할: AI에게 한 번에 전체를 맡기지 않기
# ❌ "전체 인증 시스템을 구현해줘"
# ✅ "JWT 토큰 발급 함수를 작성해줘" → PR 1
# ✅ "토큰 검증 미들웨어를 작성해줘" → PR 2
# ✅ "리프레시 토큰 로직을 추가해줘" → PR 3

# 2. Stacked PRs: 의존성이 있는 변경을 순서대로 쌓기
git checkout -b feat/auth-token       # PR 1: 토큰 발급
git checkout -b feat/auth-middleware   # PR 2: 미들웨어 (feat/auth-token 기반)
git checkout -b feat/auth-refresh     # PR 3: 리프레시 (feat/auth-middleware 기반)

# 3. 리팩토링과 기능 추가를 분리
# ❌ AI가 기능 추가와 기존 코드 리팩토링을 한 PR에 섞기
# ✅ 리팩토링 PR → 기능 추가 PR 순서로 분리`}
  language="bash"
  filename="PR 크기 관리 전략"
/>

### PR 크기 자동 제한 Hook

팀 차원에서 PR 크기를 자동으로 경고하는 Hook을 설정할 수 있습니다.

<CodeBlock
  code={`#!/bin/bash
# .claude/hooks/pr-size-check.sh
# PR에 포함된 변경 라인 수를 검사하여 경고

MAX_LINES=500
CHANGED_LINES=$(git diff --stat HEAD~1 | tail -1 | awk '{print $4+$6}')

if [ "$CHANGED_LINES" -gt "$MAX_LINES" ]; then
  echo "WARNING: 이 커밋의 변경 라인 수가 ${CHANGED_LINES}줄입니다."
  echo "PR 크기를 ${MAX_LINES}줄 이하로 유지하는 것을 권장합니다."
  echo ""
  echo "해결 방법:"
  echo "  1. 작업을 더 작은 단위로 분할하세요"
  echo "  2. 리팩토링과 기능 추가를 별도 PR로 분리하세요"
  echo "  3. AI에게 한 번에 적은 범위의 작업을 요청하세요"
fi`}
  language="bash"
  filename=".claude/hooks/pr-size-check.sh"
/>

---

## Git 워크플로우 통합

AI 코딩 에이전트를 팀의 Git 워크플로우에 자연스럽게 통합하는 전략입니다.

### 브랜치 전략

<MermaidDiagram
  chart={`gitGraph
    commit id: "init"
    branch develop
    checkout develop
    commit id: "setup"
    branch feature/auth-ai
    checkout feature/auth-ai
    commit id: "AI: JWT 토큰 발급"
    commit id: "AI: 토큰 검증 미들웨어"
    commit id: "수동: 비즈니스 로직 수정"
    checkout develop
    merge feature/auth-ai id: "PR #12 머지"
    branch feature/payment-ai
    checkout feature/payment-ai
    commit id: "AI: 결제 모듈 초안"
    commit id: "수동: 결제 로직 검증"
    checkout develop
    merge feature/payment-ai id: "PR #13 머지"
    checkout main
    merge develop id: "v1.2.0 릴리스"`}
  title="AI 협업 Git 브랜치 전략"
  caption="feature 브랜치에서 AI 생성 커밋과 수동 수정 커밋이 혼합됩니다"
/>

### 커밋 컨벤션 확장

AI 지원 커밋을 구분하기 위한 확장된 Conventional Commits 규칙입니다.

<CodeBlock
  code={`# AI 지원 커밋 컨벤션

# 기본 형식
<type>(<scope>): <description>

[body]

Co-Authored-By: Claude <noreply@anthropic.com>

# 타입별 예시
feat(auth): add JWT refresh token rotation
fix(api): resolve race condition in concurrent requests
refactor(user): simplify validation logic
test(payment): add integration tests for checkout flow
docs(api): generate OpenAPI specification

# AI 기여도를 본문에 명시하는 패턴 (선택)
feat(auth): add JWT refresh token rotation

AI가 초안을 생성하고 개발자가 다음을 수정:
- 토큰 만료 시간을 비즈니스 요구사항에 맞게 조정
- 에러 메시지를 팀 표준에 맞게 변경
- 토큰 블랙리스트 저장소를 Redis로 변경

Co-Authored-By: Claude <noreply@anthropic.com>`}
  language="text"
  filename="AI 커밋 컨벤션"
/>

### AI 커밋 추적 스크립트

Git log에서 AI 지원 커밋을 필터링하고 통계를 산출하는 스크립트입니다.

<CodeBlock
  code={`#!/bin/bash
# scripts/ai-commit-stats.sh
# AI 지원 커밋 통계 조회

echo "=== AI 지원 커밋 통계 ==="
echo ""

# 전체 커밋 수
TOTAL=$(git log --oneline --since="1 month ago" | wc -l)
echo "최근 1개월 전체 커밋: $TOTAL"

# AI 지원 커밋 수
AI_COMMITS=$(git log --since="1 month ago" --grep="Co-Authored-By: Claude" --oneline | wc -l)
echo "AI 지원 커밋: $AI_COMMITS"

# AI 커밋 비율
if [ "$TOTAL" -gt 0 ]; then
  RATIO=$((AI_COMMITS * 100 / TOTAL))
  echo "AI 커밋 비율: ${RATIO}%"
fi

echo ""
echo "=== 작성자별 AI 활용 현황 ==="
git log --since="1 month ago" --grep="Co-Authored-By: Claude" \\
  --format="%an" | sort | uniq -c | sort -rn

echo ""
echo "=== 타입별 AI 커밋 분포 ==="
git log --since="1 month ago" --grep="Co-Authored-By: Claude" \\
  --oneline | awk -F'[:(]' '{print $1}' | sort | uniq -c | sort -rn`}
  language="bash"
  filename="scripts/ai-commit-stats.sh"
/>

---

## 페어 프로그래밍 with AI

AI 에이전트를 페어 프로그래밍 파트너로 활용하는 새로운 협업 패턴입니다.
전통적인 드라이버-네비게이터 모델이 인간-AI 협업으로 확장됩니다.

### 협업 패턴 비교

<ComparisonTable
  title="페어 프로그래밍 패턴 비교"
  headers={['패턴', '구성', '장점', '적합한 상황']}
  rows={[
    { feature: '전통적 페어', values: ['인간 + 인간', '지식 전수, 실시간 리뷰', '복잡한 비즈니스 로직, 시니어-주니어 멘토링'] },
    { feature: 'AI 드라이버', values: ['AI 작성 + 인간 검토', '빠른 초안 생성, 보일러플레이트 제거', '반복적 구현, 테스트 코드 작성'] },
    { feature: 'AI 네비게이터', values: ['인간 작성 + AI 조언', '실시간 제안, 버그 탐지', '알고리즘 설계, 아키텍처 결정'] },
    { feature: '인간 + AI + 인간', values: ['AI 생성 + 두 사람 리뷰', '다각적 검증, 학습 효과', '보안 민감 코드, 핵심 비즈니스 로직'] },
  ]}
/>

### AI 드라이버 패턴: 실전 워크플로우

<CodeBlock
  code={`# AI 드라이버 패턴 예시
# 인간이 요구사항을 설명하고, AI가 코드를 작성하면 인간이 검토

# Step 1: 요구사항 명시 (인간)
> "사용자 프로필 업데이트 API를 작성해줘.
>  - PATCH /api/users/:id
>  - name, email, avatar 필드만 수정 가능
>  - email 변경 시 중복 검사
>  - 본인만 수정 가능 (인증 미들웨어 사용)
>  - 기존 UserService 패턴 따르기"

# Step 2: AI가 코드 생성 (AI)
# → controller, service, validation, test 파일 생성

# Step 3: 인간 검토 포인트
# ✅ 비즈니스 로직이 요구사항과 일치하는지
# ✅ 에러 케이스(중복 email, 권한 없음)가 처리되는지
# ✅ 기존 코드 패턴과 일관되는지
# ✅ 테스트가 주요 시나리오를 커버하는지

# Step 4: 수정 요청 (인간 → AI)
> "email 변경 시 확인 메일을 보내는 로직을 추가해줘.
>  기존 EmailService.sendVerification() 사용."

# Step 5: 반복 (필요한 만큼)`}
  language="text"
  filename="AI 드라이버 패턴 워크플로우"
/>

### AI 네비게이터 패턴: 실시간 조언

<CodeBlock
  code={`# AI 네비게이터 패턴 예시
# 인간이 코드를 작성하면서 AI에게 조언을 구함

# 상황: 복잡한 비동기 로직 작성 중

# 인간: "이 코드에서 Promise.all 대신 Promise.allSettled를
#        사용해야 하는 경우가 있을까?"
# AI: "네, 하나의 실패가 전체를 중단시키면 안 되는 경우에
#      allSettled를 사용합니다. 현재 코드에서 사용자 알림과
#      로그 기록은 독립적이므로 allSettled가 적합합니다."

# 인간: "이 재귀 함수의 시간 복잡도가 어떻게 되지?"
# AI: "현재 구현은 O(2^n)입니다. 메모이제이션을 추가하면
#      O(n)으로 개선할 수 있습니다. 예시를 보여드릴까요?"

# 인간: "이 SQL 쿼리에 보안 취약점이 있나?"
# AI: "문자열 결합으로 쿼리를 구성하고 있어 SQL Injection에
#      취약합니다. 파라미터 바인딩으로 변경하세요."`}
  language="text"
  filename="AI 네비게이터 패턴 활용"
/>

<Callout type="tip" title="하이브리드 접근">
  하나의 세션에서 패턴을 고정할 필요는 없습니다.
  보일러플레이트 생성은 AI 드라이버로, 핵심 비즈니스 로직은 AI 네비게이터로
  유연하게 전환하는 것이 가장 효과적입니다.
</Callout>

---

## 팀 교육과 온보딩

### AI 활용 교육 로드맵

<DataTable
  title="AI 활용 교육 로드맵"
  searchable={true}
  columns={[
    { key: 'stage', header: '단계', width: '80px' },
    { key: 'content', header: '교육 내용', width: '250px' },
    { key: 'target', header: '대상', width: '100px' },
    { key: 'goal', header: '목표', width: '200px' },
  ]}
  data={[
    { stage: '기초', content: 'Claude Code 설치, 기본 명령어, CLAUDE.md 이해', target: '전체 팀', goal: '기본 대화형 코딩 수행 가능' },
    { stage: '실전', content: '프롬프트 작성법, 슬래시 커맨드, Hook 활용', target: '개발자', goal: '일상 업무에 AI를 자연스럽게 활용' },
    { stage: '심화', content: '커스텀 커맨드/스킬 제작, 보안 Hook 설정', target: '시니어/리드', goal: '팀 맞춤 설정과 자동화 구축' },
    { stage: '관리', content: '가이드라인 수립, 효과 측정(Part 6 효과 측정 참조), ROI 분석', target: '매니저', goal: '조직 차원 AI 전략과 개선 사이클 운영' },
  ]}
/>

### 신규 팀원 온보딩 체크리스트

새 팀원이 AI 도구를 사용하는 팀에 합류할 때의 온보딩 절차입니다.

<CodeBlock
  code={`## 신규 팀원 AI 온보딩 체크리스트

### 1일차: 환경 설정
- [ ] Claude Code 설치 및 인증
- [ ] 프로젝트 클론 후 .claude/ 설정 자동 적용 확인
- [ ] CLAUDE.md 읽고 프로젝트 컨벤션 파악
- [ ] .claude/commands/ 목록 확인

### 1주차: 기본 활용
- [ ] 간단한 작업(테스트 작성, 문서화)으로 AI 에이전트 체험
- [ ] PR 템플릿의 "AI 지원 여부" 섹션 작성 연습
- [ ] 시니어 개발자의 AI 활용 PR을 관찰/리뷰 참여
- [ ] 팀 커스텀 커맨드 사용법 익히기

### 2주차: 실전 적용
- [ ] 실제 작업에 AI 활용하여 PR 제출
- [ ] AI 코드 리뷰 체크리스트 기반으로 동료 PR 리뷰
- [ ] 실패 사례나 의문점을 팀 채널에 공유

### 지속: 습관화
- [ ] 정기 "AI 활용 팁" 공유 미팅 참석
- [ ] 효과적인 프롬프트 패턴을 팀 위키에 기록`}
  language="markdown"
  filename="신규 팀원 AI 온보딩 체크리스트"
/>

### 온보딩 버디 시스템

신규 팀원에게 AI 활용 경험이 풍부한 "AI 버디"를 배정하는 것이 효과적입니다.

<ComparisonTable
  title="AI 버디 시스템 역할"
  headers={['기간', '버디 역할', '신규 팀원 행동']}
  rows={[
    { feature: '1주차', values: ['AI 도구 설정 지원, 기본 워크플로우 시연', '관찰하며 간단한 작업 시도'] },
    { feature: '2주차', values: ['첫 AI 활용 PR에 집중 리뷰 제공', '실전 작업에 AI 활용, 질문 적극 공유'] },
    { feature: '3~4주차', values: ['독립 작업 관찰, 필요시 조언', '독립적 AI 활용, 팀 공유 미팅에서 경험 발표'] },
    { feature: '이후', values: ['비정기 멘토링, 고급 패턴 공유', '다음 신규 팀원의 AI 버디 후보'] },
  ]}
/>

---

## 지식 공유 체계

### 프롬프트 라이브러리 운영

팀 내에서 효과적인 프롬프트를 체계적으로 관리하고 공유하는 방법입니다.

<CodeBlock
  code={`# .claude/commands/ 디렉토리를 팀 프롬프트 라이브러리로 활용

# 팀 공용 커맨드 예시 구조
.claude/
├── commands/
│   ├── pr-check.md         # PR 제출 전 점검
│   ├── code-review.md      # AI 보조 코드 리뷰
│   ├── test-generate.md    # 테스트 코드 생성
│   ├── refactor.md         # 리팩토링 가이드
│   ├── debug.md            # 디버깅 보조
│   └── api-design.md       # API 설계 가이드
├── skills/
│   ├── security-audit.md   # 보안 감사 스킬
│   ├── performance.md      # 성능 분석 스킬
│   └── migration.md        # DB 마이그레이션 스킬
└── settings.json            # 팀 공통 설정

# Git으로 버전 관리 — PR로 추가/수정 → 팀 리뷰 → 머지
# 새 커맨드를 추가할 때도 코드와 동일한 리뷰 프로세스를 거칩니다.`}
  language="text"
  filename=".claude/ 팀 라이브러리 구조"
/>

### 팀 위키 구조

프롬프트 라이브러리 외에, 팀 위키에 AI 활용 지식을 체계적으로 기록합니다.

<CodeBlock
  code={`# 팀 위키 AI 활용 섹션 구조

## AI 활용 가이드
├── 시작하기/
│   ├── 설치-및-설정.md
│   ├── 첫-번째-작업.md
│   └── FAQ.md
├── 프롬프트-패턴/
│   ├── 코드-생성-패턴.md          # "~를 구현해줘" 유형별 모범 프롬프트
│   ├── 리팩토링-패턴.md          # "~를 개선해줘" 유형별 모범 프롬프트
│   ├── 디버깅-패턴.md            # "~가 안 되는데" 유형별 모범 프롬프트
│   └── 안티-패턴.md              # 피해야 할 프롬프트 모음
├── 사례-아카이브/
│   ├── 성공-사례.md              # 효과적이었던 AI 활용 사례
│   ├── 실패-사례.md              # 주의가 필요한 AI 활용 사례
│   └── 주간-회고-기록.md         # AI 활용 회고 미팅 기록
└── 가이드라인/
    ├── 코드-리뷰-규칙.md
    ├── PR-작성-규칙.md
    └── 보안-규칙.md`}
  language="text"
  filename="팀 위키 AI 활용 섹션"
/>

### 실패 사례 공유의 가치

성공 사례보다 **실패 사례**가 팀 학습에 더 큰 가치를 줍니다.

<ComparisonTable
  title="팀 공유 추천 사례"
  headers={['유형', '공유 내용', '학습 효과']}
  rows={[
    { feature: '환각 사례', values: ['AI가 존재하지 않는 패키지/API를 추천한 경우', '리뷰 시 검증 습관 형성'] },
    { feature: '과도한 복잡성', values: ['AI가 불필요한 패턴을 추가한 경우', '간결한 코드 요구 방법 학습'] },
    { feature: '보안 실수', values: ['AI가 시크릿을 하드코딩한 경우', 'Hook 자동 검사의 중요성 인식'] },
    { feature: '대형 PR', values: ['AI에게 전체를 맡겨 리뷰 불가 PR이 된 경우', '작업 분할 전략 학습'] },
    { feature: '효과적 프롬프트', values: ['명확한 프롬프트로 좋은 결과를 얻은 경우', '프롬프트 패턴 라이브러리 확장'] },
  ]}
/>

<Callout type="tip" title="정기 공유 미팅">
  주간 또는 격주로 15~30분 "AI 활용 회고" 미팅을 권장합니다.
  각자 한 가지씩 성공 또는 실패 사례를 공유하고,
  유용한 패턴은 `.claude/commands/`에, 주의사항은 CLAUDE.md에 반영합니다.
</Callout>

---

## Agent Teams로 팀 생산성 극대화

2026년 2월 출시된 **Agent Teams**를 팀 단위로 활용하는 패턴입니다.
하나의 작업을 여러 에이전트에게 병렬로 분배하여, 개발-테스트-문서화를 동시에 진행할 수 있습니다.

### 팀 워크플로우에 Agent Teams 통합

<MermaidDiagram
  chart={`flowchart TB
    PM["PM: 요구사항 정의"] --> TL["Team Lead: Agent Teams 구성"]
    TL --> FE["Agent 1: 프론트엔드"]
    TL --> BE["Agent 2: 백엔드"]
    TL --> QA["Agent 3: 테스트"]
    TL --> DOC["Agent 4: 문서"]
    FE --> INT["통합 & 코드 리뷰"]
    BE --> INT
    QA --> INT
    DOC --> INT
    INT --> REVIEW["인간 리뷰어 검토"]
    REVIEW --> DEPLOY["배포"]

    style PM fill:#e8f5e9,stroke:#4caf50,color:#333
    style DEPLOY fill:#e8f5e9,stroke:#4caf50,color:#333
    style REVIEW fill:#fff9c4,stroke:#f9a825,color:#333`}
  title="Agent Teams 기반 팀 워크플로우"
  caption="PM이 요구사항을 정의하면, Agent Teams가 병렬로 작업하고 인간 리뷰어가 최종 검토합니다"
/>

### Agent Teams 작업 분배 패턴

<CodeBlock
  code={`# Agent Teams 작업 분배 예시

## 시나리오: 사용자 대시보드 기능 구현

### 오케스트레이터 (Team Lead가 설정)
"사용자 대시보드 기능을 구현합니다.
 다음 에이전트에게 각각 작업을 분배합니다:"

### Agent 1: 프론트엔드
"React 대시보드 컴포넌트를 구현하세요:
 - DashboardPage, StatCard, ActivityFeed 컴포넌트
 - 기존 디자인 시스템 컴포넌트 활용
 - Storybook 스토리 포함"

### Agent 2: 백엔드
"대시보드 API 엔드포인트를 구현하세요:
 - GET /api/dashboard/stats
 - GET /api/dashboard/activity
 - 기존 UserService, ActivityService 활용"

### Agent 3: 테스트
"대시보드 기능의 테스트를 작성하세요:
 - API 통합 테스트
 - 컴포넌트 단위 테스트
 - E2E 시나리오 (Playwright)"

### Agent 4: 문서
"대시보드 API 문서를 작성하세요:
 - OpenAPI 스펙 업데이트
 - README에 기능 설명 추가"

### 통합 규칙
- 각 에이전트는 별도 브랜치에서 작업
- 인터페이스(API 스펙)는 오케스트레이터가 먼저 확정
- 모든 에이전트 작업 완료 후 인간 리뷰어가 통합 검토`}
  language="markdown"
  filename="Agent Teams 작업 분배 패턴"
/>

### Agent Teams 사용 시 주의사항

<ComparisonTable
  title="Agent Teams 활용 권장/주의 사항"
  headers={['상황', '권장도', '이유']}
  rows={[
    { feature: '독립적 모듈 병렬 개발', values: ['yes', '에이전트 간 의존성이 낮아 충돌 최소화'] },
    { feature: 'API + 프론트 + 테스트 동시', values: ['yes', '인터페이스만 먼저 합의하면 병렬 가능'] },
    { feature: '같은 파일 수정', values: ['no', '머지 충돌이 빈번하게 발생'] },
    { feature: '순차적 의존성 작업', values: ['no', '이전 에이전트 결과에 의존하므로 직렬이 적합'] },
    { feature: '보안 민감 코드', values: ['partial', '반드시 인간 리뷰어의 심층 검토 필요'] },
  ]}
/>

---

## Cowork로 비개발자 협업

2026년 1월 출시된 **Claude Cowork**는 PM, 디자이너, QA 등 비개발자도 AI 에이전트를 활용할 수 있게 합니다.

### Cowork 역할별 활용

<ComparisonTable
  title="Cowork 역할별 활용"
  headers={['역할', 'Cowork 활용', '효과']}
  rows={[
    { feature: 'PM', values: ['요구사항 문서 자동 정리, PRD에서 기술 스펙 초안 생성', '기획-개발 간 의사소통 시간 단축'] },
    { feature: 'QA', values: ['테스트 시나리오 자동 생성, 리그레션 테스트 스크립트 작성', '수동 테스트 시간 50%+ 감소'] },
    { feature: '디자이너', values: ['Figma 목업에서 컴포넌트 스펙 추출, 디자인 토큰 문서화', '디자인 핸드오프 자동화'] },
    { feature: '테크니컬 라이터', values: ['API 문서 초안 자동 작성, 코드 변경에 따른 문서 업데이트 감지', '문서-코드 동기화 보장'] },
  ]}
/>

### Cowork 팀 워크플로우

<MermaidDiagram
  chart={`flowchart LR
    subgraph NON_DEV["비개발자 영역"]
      PM["PM: PRD 작성"] --> SPEC["Cowork: 기술 스펙 초안"]
      QA_H["QA: 시나리오 정의"] --> TEST_GEN["Cowork: 테스트 스크립트"]
      DESIGN["디자이너: 목업 완성"] --> TOKEN["Cowork: 디자인 토큰 추출"]
    end

    subgraph DEV["개발자 영역"]
      SPEC --> DEV_IMPL["개발자: 구현"]
      TOKEN --> DEV_IMPL
      DEV_IMPL --> AI_CODE["Claude Code: 코드 생성"]
      AI_CODE --> REVIEW["코드 리뷰"]
    end

    subgraph VERIFY["검증 영역"]
      REVIEW --> MERGE["머지"]
      TEST_GEN --> E2E["E2E 테스트 실행"]
      MERGE --> E2E
      E2E --> DEPLOY["배포"]
    end

    style NON_DEV fill:#e3f2fd,stroke:#1976d2,color:#333
    style DEV fill:#fff3e0,stroke:#f57c00,color:#333
    style VERIFY fill:#e8f5e9,stroke:#4caf50,color:#333`}
  title="Cowork 기반 크로스 팀 워크플로우"
  caption="비개발자도 Cowork를 통해 개발 파이프라인에 직접 기여합니다"
/>

---

## 갈등 해결: AI 생성 코드에 대한 의견 충돌

AI 생성 코드가 팀에 도입되면 새로운 유형의 갈등이 발생할 수 있습니다.
이를 사전에 인지하고 해결 프로세스를 마련해야 합니다.

### 흔한 갈등 유형

<ComparisonTable
  title="AI 코드 관련 갈등 유형과 해결 방법"
  headers={['갈등 유형', '상황 예시', '해결 접근법']}
  rows={[
    { feature: '코드 소유권', values: ['AI가 작성한 코드의 품질에 대해 누가 책임지는가', '커밋한 사람이 소유자, 팀 가이드라인에 명문화'] },
    { feature: '스타일 불일치', values: ['AI가 팀 컨벤션과 다른 스타일로 코드를 생성', 'CLAUDE.md에 컨벤션 상세화, 린트 규칙 강화'] },
    { feature: '과도한 의존', values: ['특정 팀원이 AI에 지나치게 의존하여 이해도 부족', '코드 리뷰에서 이해도 확인 질문 의무화'] },
    { feature: '기술 부채 우려', values: ['AI가 빠르게 만든 코드가 장기 유지보수에 부적합', '정기 리팩토링 스프린트, 기술 부채 지표 추적'] },
    { feature: '도구 선호 차이', values: ['팀원마다 다른 AI 도구/설정을 원함', '팀 공통 설정은 통일, 개인 설정은 local 파일로 허용'] },
  ]}
/>

### 갈등 해결 프로세스

<CodeBlock
  code={`## AI 코드 갈등 해결 프로세스

### 1단계: 문제 식별
- 리뷰 코멘트에서 반복되는 패턴 파악
- 회고 미팅에서 불만/우려 수집
- 코드 품질 메트릭으로 객관적 확인

### 2단계: 팀 토론
- 관련 당사자 모두 참여
- 구체적 코드 예시 기반 토론 (감정이 아닌 코드 중심)
- "이 코드의 문제는 무엇인가?"로 시작

### 3단계: 합의 도출
- CLAUDE.md 또는 팀 가이드라인에 합의 내용 반영
- Hook이나 린트 규칙으로 자동화 가능한 부분 처리
- 합의 결과를 PR로 만들어 전체 팀에 공유

### 4단계: 모니터링
- 다음 스프린트에서 같은 갈등이 재발하는지 확인
- 효과가 없으면 2단계로 돌아가 재논의

### 에스컬레이션 기준
- 2회 이상 같은 갈등 반복 → 팀 리드 중재
- 보안 관련 갈등 → 보안 담당자 참여 필수
- 아키텍처 관련 갈등 → 아키텍트/CTO 의견 요청`}
  language="markdown"
  filename="AI 코드 갈등 해결 프로세스"
/>

<Callout type="info" title="심리적 안전감이 핵심">
  AI 코드에 대한 의문을 제기하는 것이 자연스러운 문화를 만드세요.
  "이 코드 AI가 만든 거죠? 왜 이런 구조인지 잘 모르겠는데 설명해주실 수 있나요?"가
  부정적인 비판이 아닌 건강한 질문으로 받아들여지는 환경이 중요합니다.
</Callout>

---

## 팀 메트릭과 대시보드

AI 도구 도입 후 팀 성과를 추적하기 위한 핵심 메트릭과 대시보드 설계입니다.

### 핵심 추적 메트릭

<DataTable
  title="AI 협업 팀 메트릭"
  searchable={true}
  columns={[
    { key: 'metric', header: '메트릭', width: '150px' },
    { key: 'how', header: '측정 방법', width: '200px' },
    { key: 'target', header: '목표', width: '120px' },
    { key: 'warning', header: '경고 신호', width: '180px' },
  ]}
  data={[
    { metric: 'PR 리뷰 시간', how: 'PR 생성 ~ 최종 승인 평균', target: '24시간 이내', warning: '48시간 초과 시 리뷰 병목' },
    { metric: 'PR 크기', how: '변경 라인 수 중앙값', target: '200줄 이하', warning: '500줄 초과 PR 비율 30% 이상' },
    { metric: 'AI 커밋 비율', how: 'Co-Authored-By 태그 기준', target: '팀 기준선 설정', warning: '급격한 변동 (상승/하강)' },
    { metric: '리뷰 반려율', how: 'PR 반려 수 / 전체 PR 수', target: '20% 이하', warning: '30% 초과 시 품질 문제' },
    { metric: '인시던트 발생률', how: 'AI 관련 장애 건수/월', target: '0건', warning: '1건 이상 시 프로세스 점검' },
    { metric: '온보딩 완료 시간', how: '입사 ~ 첫 AI 활용 PR까지', target: '2주 이내', warning: '4주 초과 시 교육 과정 개선' },
    { metric: '프롬프트 공유 빈도', how: '위키/커맨드 업데이트 횟수/월', target: '월 3회 이상', warning: '1개월 이상 업데이트 없음' },
  ]}
/>

### 대시보드 설계

<CodeBlock
  code={`# 팀 AI 협업 대시보드 자동 생성 스크립트
# scripts/team-dashboard.sh

#!/bin/bash

echo "========================================="
echo "  팀 AI 협업 대시보드"
echo "  생성 일시: $(date '+%Y-%m-%d %H:%M')"
echo "========================================="
echo ""

# 1. 이번 주 PR 현황
echo "--- PR 현황 (이번 주) ---"
gh pr list --state all --search "created:>=$(date -d '7 days ago' '+%Y-%m-%d')" \\
  --json number,title,state,createdAt,mergedAt \\
  --template '{{range .}}#{{.number}} [{{.state}}] {{.title}}{{"\n"}}{{end}}'
echo ""

# 2. AI 커밋 비율
echo "--- AI 커밋 비율 (최근 7일) ---"
TOTAL=$(git log --since="7 days ago" --oneline | wc -l)
AI=$(git log --since="7 days ago" --grep="Co-Authored-By" --oneline | wc -l)
echo "전체: $TOTAL / AI 지원: $AI ($(( AI * 100 / (TOTAL + 1) ))%)"
echo ""

# 3. 작성자별 AI 활용
echo "--- 작성자별 AI 활용 (최근 7일) ---"
git log --since="7 days ago" --grep="Co-Authored-By" \\
  --format="%an" | sort | uniq -c | sort -rn
echo ""

# 4. PR 크기 분포
echo "--- PR 크기 분포 ---"
gh pr list --state merged --limit 20 \\
  --json number,additions,deletions \\
  --template '{{range .}}#{{.number}}: +{{.additions}} -{{.deletions}} ({{add .additions .deletions}} lines){{"\n"}}{{end}}'
echo ""

echo "========================================="
echo "  상세 분석: Part 6 효과 측정 챕터 참조"
echo "========================================="`}
  language="bash"
  filename="scripts/team-dashboard.sh"
/>

### 주간 팀 리포트 자동화

<CodeBlock
  code={`---
description: 주간 AI 협업 리포트를 생성합니다
---

다음 데이터를 수집하고 정리하세요:

1. 최근 7일간 머지된 PR 목록과 AI 사용 여부
2. PR별 리뷰 소요 시간 (생성 ~ 승인)
3. 리뷰에서 반복되는 이슈 패턴 식별
4. AI 커밋 비율과 이전 주 대비 변화
5. 새로 공유된 프롬프트/커맨드 목록

리포트를 다음 형식으로 출력:
- 핵심 수치 요약 (3줄)
- 주요 변화 사항 (증감, 특이사항)
- 다음 주 개선 제안 (1~2개)
- 공유할 만한 좋은 사례 (있다면)`}
  language="markdown"
  filename=".claude/commands/weekly-report.md"
/>

---

## 엔터프라이즈 도입 사례

### 도입 사례 비교

<ComparisonTable
  title="엔터프라이즈 AI 에이전트 도입 사례"
  headers={['기업', '규모', '성과', '출처']}
  rows={[
    { feature: 'Ramp (핀테크)', values: ['엔지니어링 팀 전체', '30일간 100만줄+ AI 코드, 인시던트 80% 감소', 'Anthropic 블로그'] },
    { feature: 'Bridgewater (헤지펀드)', values: ['투자 분석팀', '주니어 애널리스트 수준의 투자 분석 자동화', 'Amazon Bedrock 사례'] },
    { feature: 'Anthropic 내부', values: ['보안/마케팅/법무팀', '프로덕션 이슈 해결 67% 단축', '공식 블로그'] },
  ]}
/>

### 도입 단계별 로드맵

<MermaidDiagram
  chart={`flowchart LR
    subgraph P1["Phase 1: 파일럿 (1~2개월)"]
      A1["2~3명 선발팀"]
      A2["기본 설정 구축"]
      A3["초기 가이드라인"]
    end

    subgraph P2["Phase 2: 확산 (2~4개월)"]
      B1["팀 전체 교육"]
      B2["가이드라인 고도화"]
      B3["메트릭 수집 시작"]
    end

    subgraph P3["Phase 3: 최적화 (4~6개월)"]
      C1["Agent Teams 도입"]
      C2["Cowork 확장"]
      C3["ROI 분석/개선"]
    end

    subgraph P4["Phase 4: 성숙 (6개월+)"]
      D1["조직 전체 확산"]
      D2["표준 프로세스화"]
      D3["지속적 개선 사이클"]
    end

    P1 --> P2
    P2 --> P3
    P3 --> P4

    style P1 fill:#e3f2fd,stroke:#1976d2,color:#333
    style P2 fill:#fff3e0,stroke:#f57c00,color:#333
    style P3 fill:#e8f5e9,stroke:#4caf50,color:#333
    style P4 fill:#f3e5f5,stroke:#9c27b0,color:#333`}
  title="AI 에이전트 팀 도입 로드맵"
  caption="파일럿에서 시작하여 점진적으로 확산하는 4단계 접근법"
/>

### 도입 시 흔한 실수와 대응

<ComparisonTable
  title="AI 도입 흔한 실수와 대응"
  headers={['실수', '결과', '대응']}
  rows={[
    { feature: '가이드라인 없이 도입', values: ['코드 품질 편차 심화, 보안 사고 위험', 'CLAUDE.md와 팀 설정을 먼저 준비'] },
    { feature: '한 번에 전체 도입', values: ['교육 부담, 저항감, 혼란', '파일럿 팀으로 시작하여 단계적 확산'] },
    { feature: '메트릭 미수집', values: ['효과 증명 불가, 개선 방향 모호', '도입 초기부터 기준선 메트릭 수집'] },
    { feature: '리뷰 프로세스 미변경', values: ['PR 병목, 리뷰 시간 급증', 'AI 코드 리뷰 3단계 프로세스 도입'] },
    { feature: '교육 생략', values: ['비효율적 사용, AI 환각 미감지', '단계별 교육 로드맵 운영'] },
  ]}
/>

<Callout type="info" title="팀 전체의 도구로 확장">
  Agent Teams와 Cowork는 '개발자만의 도구'에서 '팀 전체의 도구'로 AI 에이전트의 활용 범위를 확장합니다.
  성공적인 도입의 핵심은 기술이 아닌 **프로세스와 문화의 변화**입니다.
</Callout>

---

<ChapterNav
  prev={{ title: '보안', path: '/docs/part-6--모범-사례-보안' }}
  next={{ title: '효과 측정', path: '/docs/part-6--모범-사례-효과-측정' }}
/>
